module M_binary_search
  use creusot.int.UInt64
  use seq.Seq
  use creusot.int.UInt32
  use mach.int.Int
  use creusot.prelude.Any
  
  type t_Vec_u32_Global
  
  constant const_MAX: UInt64.t = (18446744073709551615: UInt64.t)
  
  function view_Vec_u32_Global (self: t_Vec_u32_Global) : Seq.seq UInt32.t
  
  axiom view_Vec_u32_Global_spec: forall self: t_Vec_u32_Global. Seq.length (view_Vec_u32_Global self)
      <= UInt64.t'int const_MAX
  
  let rec len_u32 (self_: t_Vec_u32_Global) (return (x: UInt64.t)) = any
    [ return (result: UInt64.t) -> {UInt64.t'int result = Seq.length (view_Vec_u32_Global self_)} (! return {result}) ]
  
  type t_Result_usize_usize = Ok UInt64.t | Err UInt64.t
  
  type t_Ordering = Less | Equal | Greater
  
  function cmp_log_u32 (self: UInt32.t) (o: UInt32.t) : t_Ordering = if UInt32.lt self o then
      Less
    else
      if self = o then Equal else Greater
  
  
  function eq_cmp_u32 (x: UInt32.t) (y: UInt32.t) : ()
  
  axiom eq_cmp_u32_spec: forall x: UInt32.t, y: UInt32.t. (x = y) = (cmp_log_u32 x y = Equal)
  
  function antisym2_u32 (x: UInt32.t) (y: UInt32.t) : ()
  
  axiom antisym2_u32_spec: forall x: UInt32.t, y: UInt32.t. cmp_log_u32 x y = Greater -> cmp_log_u32 y x = Less
  
  function antisym1_u32 (x: UInt32.t) (y: UInt32.t) : ()
  
  axiom antisym1_u32_spec: forall x: UInt32.t, y: UInt32.t. cmp_log_u32 x y = Less -> cmp_log_u32 y x = Greater
  
  function trans_u32 (x: UInt32.t) (y: UInt32.t) (z: UInt32.t) (o: t_Ordering) : ()
  
  axiom trans_u32_spec: forall x: UInt32.t, y: UInt32.t, z: UInt32.t, o: t_Ordering. cmp_log_u32 x y = o
      -> cmp_log_u32 y z = o -> cmp_log_u32 x z = o
  
  function refl_u32 (x: UInt32.t) : ()
  
  axiom refl_u32_spec: forall x: UInt32.t. cmp_log_u32 x x = Equal
  
  function cmp_gt_log_u32 (x: UInt32.t) (y: UInt32.t) : ()
  
  axiom cmp_gt_log_u32_spec: forall x: UInt32.t, y: UInt32.t. UInt32.gt x y = (cmp_log_u32 x y = Greater)
  
  function cmp_ge_log_u32 (x: UInt32.t) (y: UInt32.t) : ()
  
  axiom cmp_ge_log_u32_spec: forall x: UInt32.t, y: UInt32.t. UInt32.ge x y = (cmp_log_u32 x y <> Less)
  
  function cmp_lt_log_u32 (x: UInt32.t) (y: UInt32.t) : ()
  
  axiom cmp_lt_log_u32_spec: forall x: UInt32.t, y: UInt32.t. UInt32.lt x y = (cmp_log_u32 x y = Less)
  
  function cmp_le_log_u32 (x: UInt32.t) (y: UInt32.t) : ()
  
  axiom cmp_le_log_u32_spec: forall x: UInt32.t, y: UInt32.t. UInt32.le x y = (cmp_log_u32 x y <> Greater)
  
  function index_Vec_u32_Global [@inline:trivial] (self: t_Vec_u32_Global) (ix: int) : UInt32.t =
    Seq.get (view_Vec_u32_Global self) ix
  
  meta "rewrite_def" function index_Vec_u32_Global
  
  function cmp_log_usize (self: UInt64.t) (o: UInt64.t) : t_Ordering = if UInt64.lt self o then
      Less
    else
      if self = o then Equal else Greater
  
  
  function eq_cmp_usize (x: UInt64.t) (y: UInt64.t) : ()
  
  axiom eq_cmp_usize_spec: forall x: UInt64.t, y: UInt64.t. (x = y) = (cmp_log_usize x y = Equal)
  
  function antisym2_usize (x: UInt64.t) (y: UInt64.t) : ()
  
  axiom antisym2_usize_spec: forall x: UInt64.t, y: UInt64.t. cmp_log_usize x y = Greater -> cmp_log_usize y x = Less
  
  function antisym1_usize (x: UInt64.t) (y: UInt64.t) : ()
  
  axiom antisym1_usize_spec: forall x: UInt64.t, y: UInt64.t. cmp_log_usize x y = Less -> cmp_log_usize y x = Greater
  
  function trans_usize (x: UInt64.t) (y: UInt64.t) (z: UInt64.t) (o: t_Ordering) : ()
  
  axiom trans_usize_spec: forall x: UInt64.t, y: UInt64.t, z: UInt64.t, o: t_Ordering. cmp_log_usize x y = o
      -> cmp_log_usize y z = o -> cmp_log_usize x z = o
  
  function refl_usize (x: UInt64.t) : ()
  
  axiom refl_usize_spec: forall x: UInt64.t. cmp_log_usize x x = Equal
  
  function cmp_gt_log_usize (x: UInt64.t) (y: UInt64.t) : ()
  
  axiom cmp_gt_log_usize_spec: forall x: UInt64.t, y: UInt64.t. UInt64.gt x y = (cmp_log_usize x y = Greater)
  
  function cmp_ge_log_usize (x: UInt64.t) (y: UInt64.t) : ()
  
  axiom cmp_ge_log_usize_spec: forall x: UInt64.t, y: UInt64.t. UInt64.ge x y = (cmp_log_usize x y <> Less)
  
  function cmp_lt_log_usize (x: UInt64.t) (y: UInt64.t) : ()
  
  axiom cmp_lt_log_usize_spec: forall x: UInt64.t, y: UInt64.t. UInt64.lt x y = (cmp_log_usize x y = Less)
  
  function cmp_le_log_usize (x: UInt64.t) (y: UInt64.t) : ()
  
  axiom cmp_le_log_usize_spec: forall x: UInt64.t, y: UInt64.t. UInt64.le x y = (cmp_log_usize x y <> Greater)
  
  predicate in_bounds_usize [@inline:trivial] (self: UInt64.t) (seq: Seq.seq UInt32.t) =
    UInt64.t'int self < Seq.length seq
  
  meta "rewrite_def" predicate in_bounds_usize
  
  predicate has_value_usize [@inline:trivial] (self: UInt64.t) (seq: Seq.seq UInt32.t) (out: UInt32.t) =
    Seq.get seq (UInt64.t'int self) = out
  
  meta "rewrite_def" predicate has_value_usize
  
  let rec index_Vec_u32_Global'0 (self_: t_Vec_u32_Global) (ix: UInt64.t) (return (x: UInt32.t)) =
    {[@expl:index requires] in_bounds_usize ix (view_Vec_u32_Global self_)}
    any [ return (result: UInt32.t) -> {has_value_usize ix (view_Vec_u32_Global self_) result} (! return {result}) ]
  
  predicate sorted_range (s: Seq.seq UInt32.t) (l: int) (u: int) =
    forall i: int, j: int. l <= i /\ i < j /\ j < u -> UInt32.le (Seq.get s i) (Seq.get s j)
  
  predicate sorted (s: Seq.seq UInt32.t) = sorted_range s 0 (Seq.length s)
  
  meta "compute_max_steps" 1000000
  
  meta "select_lsinst" "all"
  
  let rec binary_search (arr: t_Vec_u32_Global) (elem: UInt32.t) (return (x: t_Result_usize_usize)) =
    {[@expl:binary_search requires #0] Seq.length (view_Vec_u32_Global arr) <= UInt64.t'int const_MAX}
    {[@expl:binary_search requires #1] sorted (view_Vec_u32_Global arr)}
    (! bb0
    [ bb0 = s0 [ s0 = len_u32 {arr} (fun (_ret: UInt64.t) -> [ &_10 <- _ret ] s1) | s1 = bb1 ]
    | bb1 = s0
      [ s0 = [ &_9 <- _10 = (0: UInt64.t) ] s1 | s1 = any [ br0 -> {_9 = false} (! bb3) | br1 -> {_9} (! bb2) ] ]
    | bb2 = s0 [ s0 = [ &_0 <- Err (0: UInt64.t) ] s1 | s1 = bb21 ]
    | bb3 = s0 [ s0 = len_u32 {arr} (fun (_ret: UInt64.t) -> [ &size <- _ret ] s1) | s1 = bb4 ]
    | bb4 = s0 [ s0 = [ &base <- (0: UInt64.t) ] s1 | s1 = bb5 ]
    | bb5 = bb5
      [ bb5 = {[@expl:loop invariant #0] 0 < UInt64.t'int size
        /\ UInt64.t'int size + UInt64.t'int base <= Seq.length (view_Vec_u32_Global arr)}
        {[@expl:loop invariant #1] forall i: UInt64.t. UInt64.lt i base
          -> UInt32.le (index_Vec_u32_Global arr (UInt64.t'int i)) elem}
        {[@expl:loop invariant #2] forall i: UInt64.t. UInt64.t'int base + UInt64.t'int size < UInt64.t'int i
            /\ UInt64.t'int i < Seq.length (view_Vec_u32_Global arr)
          -> UInt32.lt elem (index_Vec_u32_Global arr (UInt64.t'int i))}
        (! s0)
        [ s0 = bb6 ]
        [ bb6 = s0
          [ s0 = [ &_22 <- UInt64.gt size (1: UInt64.t) ] s1
          | s1 = any [ br0 -> {_22 = false} (! bb13) | br1 -> {_22} (! bb7) ] ]
        | bb7 = s0
          [ s0 = [ &_26 <- (2: UInt64.t) = (0: UInt64.t) ] s1 | s1 = {[@expl:division by zero] not _26} s2 | s2 = bb8 ]
        | bb8 = s0
          [ s0 = UInt64.div {size} {(2: UInt64.t)} (fun (_ret: UInt64.t) -> [ &half <- _ret ] s1)
          | s1 = UInt64.add {base} {half} (fun (_ret: UInt64.t) -> [ &mid <- _ret ] s2)
          | s2 = index_Vec_u32_Global'0 {arr} {mid} (fun (_ret: UInt32.t) -> [ &_33 <- _ret ] s3)
          | s3 = bb9 ]
        | bb9 = s0
          [ s0 = [ &_31 <- UInt32.gt _33 elem ] s1
          | s1 = any [ br0 -> {_31 = false} (! bb11) | br1 -> {_31} (! bb10) ] ]
        | bb10 = s0 [ s0 = [ &_30 <- base ] s1 | s1 = bb12 ]
        | bb11 = s0 [ s0 = [ &_30 <- mid ] s1 | s1 = bb12 ]
        | bb12 = s0
          [ s0 = [ &base <- _30 ] s1
          | s1 = UInt64.sub {size} {half} (fun (_ret: UInt64.t) -> [ &size <- _ret ] s2)
          | s2 = bb5 ] ] ]
    | bb13 = s0 [ s0 = index_Vec_u32_Global'0 {arr} {base} (fun (_ret: UInt32.t) -> [ &_40 <- _ret ] s1) | s1 = bb14 ]
    | bb14 = s0
      [ s0 = [ &cmp <- _40 ] s1
      | s1 = [ &_43 <- cmp = elem ] s2
      | s2 = any [ br0 -> {_43 = false} (! bb16) | br1 -> {_43} (! bb15) ] ]
    | bb15 = s0 [ s0 = [ &_0 <- Ok base ] s1 | s1 = bb21 ]
    | bb16 = s0
      [ s0 = [ &_47 <- UInt32.lt cmp elem ] s1 | s1 = any [ br0 -> {_47 = false} (! bb18) | br1 -> {_47} (! bb17) ] ]
    | bb17 = s0
      [ s0 = UInt64.add {base} {(1: UInt64.t)} (fun (_ret: UInt64.t) -> [ &_50 <- _ret ] s1)
      | s1 = [ &_0 <- Err _50 ] s2
      | s2 = bb21 ]
    | bb18 = s0 [ s0 = [ &_0 <- Err base ] s1 | s1 = bb21 ]
    | bb21 = return {_0} ]
    [ & _0: t_Result_usize_usize = Any.any_l ()
    | & arr: t_Vec_u32_Global = arr
    | & elem: UInt32.t = elem
    | & _9: bool = Any.any_l ()
    | & _10: UInt64.t = Any.any_l ()
    | & size: UInt64.t = Any.any_l ()
    | & base: UInt64.t = Any.any_l ()
    | & _22: bool = Any.any_l ()
    | & half: UInt64.t = Any.any_l ()
    | & _26: bool = Any.any_l ()
    | & mid: UInt64.t = Any.any_l ()
    | & _30: UInt64.t = Any.any_l ()
    | & _31: bool = Any.any_l ()
    | & _33: UInt32.t = Any.any_l ()
    | & cmp: UInt32.t = Any.any_l ()
    | & _40: UInt32.t = Any.any_l ()
    | & _43: bool = Any.any_l ()
    | & _47: bool = Any.any_l ()
    | & _50: UInt64.t = Any.any_l () ])
    [ return (result: t_Result_usize_usize) -> {[@expl:binary_search ensures #0] forall x: UInt64.t. result = Ok x
        -> index_Vec_u32_Global arr (UInt64.t'int x) = elem}
      {[@expl:binary_search ensures #1] forall x: UInt64.t. result = Err x
        -> (forall i: UInt64.t. UInt64.lt i x -> UInt32.le (index_Vec_u32_Global arr (UInt64.t'int i)) elem)}
      {[@expl:binary_search ensures #2] forall x: UInt64.t. result = Err x
        -> (forall i: UInt64.t. UInt64.lt x i /\ UInt64.t'int i < Seq.length (view_Vec_u32_Global arr)
          -> UInt32.lt elem (index_Vec_u32_Global arr (UInt64.t'int i)))}
      (! return {result}) ]
end
